{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW2\n",
    "# Problem 1 (Impact of different activation functions and optimization on learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(a) what is the exact number of parameters we are trying to learn?\n",
    "(b) use different activation functions in your architecture \n",
    "(e.g. sigmoid for 1st layer, tanh for 2nd layer, sigmoid for 3rd layer, reLU for 4th layer, and leaky reLu for 5th layer) \n",
    "and assess its impact on accuracy?\n",
    "(c) for part (b) keep the same architecture, just use different optimization routine and assess its impact on accuracy?\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T22:06:31.051382Z",
     "start_time": "2018-09-17T22:06:26.487771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyingellie/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-308a1721ee59>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/liyingellie/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/liyingellie/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/liyingellie/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/liyingellie/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/liyingellie/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#load MNIST dataset \n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T22:06:31.107135Z",
     "start_time": "2018-09-17T22:06:31.090083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "#--------------------------------\n",
    "# learning rate\n",
    "learning_rate = 0.05\n",
    "\n",
    "#training_epochs = 1000\n",
    "#batch_size = 30\n",
    "\n",
    "training_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "display_step = 2\n",
    "\n",
    "#Network Architecture\n",
    "# -----------------------------------------\n",
    "#\n",
    "# Two hidden layers\n",
    "#\n",
    "#------------------------------------------\n",
    "# number of neurons in layer 1\n",
    "n_hidden_1 = 400\n",
    "# number of neurons in layer 2\n",
    "n_hidden_2 = 200\n",
    "# number of neurons in layer 3\n",
    "n_hidden_3 = 100\n",
    "# number of neurons in layer 4\n",
    "n_hidden_4 = 50\n",
    "# number of neurons in layer 5\n",
    "n_hidden_5 = 25\n",
    "\n",
    "#MNIST data image of shape 28*28=784\n",
    "input_size = 784\n",
    "\n",
    "# 0-9 digits recognition (labels)\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(x, weight_shape, bias_shape, name):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape the the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    # comes from the study by He et al. for ReLU layers\n",
    "    w_std = (2.0/weight_shape[0])**0.5\n",
    "    #print(weight_shape[0])\n",
    "    #w_std = 0.5;\n",
    "\n",
    "    #initialization of the weights\n",
    "    #you can try either\n",
    "    w_0 = tf.random_normal_initializer(stddev=w_std)\n",
    "    #w_0 = tf.random_uniform_initializer(minval=-1,maxval=1)\n",
    "\n",
    "    b_0 = tf.constant_initializer(value=0)\n",
    "    \n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=w_0)\n",
    "    b = tf.get_variable(\"b\", bias_shape,   initializer=b_0)\n",
    "    \n",
    "    print('Weight Matrix:', W)\n",
    "    print('Bias Vector:', b)\n",
    "    \n",
    "    if name == 'linear':\n",
    "        return tf.matmul(x, W) + b\n",
    "    elif name == 'tanh':\n",
    "        return tf.nn.tanh(tf.matmul(x, W) + b)\n",
    "    elif name == 'sigmoid':\n",
    "        return tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "    elif name == 'ReLU':\n",
    "        return tf.nn.relu(tf.matmul(x, W) + b)\n",
    "        \n",
    "        \n",
    "    # different activation functions\n",
    "    # you can try\n",
    "    # (1) linear activation (not a good idea)\n",
    "    #return tf.matmul(x, W) + b\n",
    "    # (2) tanh activation\n",
    "    #return tf.nn.tanh(tf.matmul(x, W) + b)\n",
    "    # (3) sigmoid activation\n",
    "    #return tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "    # (4) relu activation\n",
    "    # return tf.nn.relu(tf.matmul(x, W) + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Layer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(x, weight_shape, bias_shape, name):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape the the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    # comes from the study by He et al. for ReLU layers\n",
    "    w_std = (2.0/weight_shape[0])**0.5\n",
    "    #print(weight_shape[0])\n",
    "    #w_std = 0.5;\n",
    "\n",
    "    #initialization of the weights\n",
    "    #you can try either\n",
    "    w_0 = tf.random_normal_initializer(stddev=w_std)\n",
    "    #w_0 = tf.random_uniform_initializer(minval=-1,maxval=1)\n",
    "\n",
    "    b_0 = tf.constant_initializer(value=0)\n",
    "    \n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=w_0)\n",
    "    b = tf.get_variable(\"b\", bias_shape,   initializer=b_0)\n",
    "    \n",
    "    print('Weight Matrix:', W)\n",
    "    print('Bias Vector:', b)\n",
    "    \n",
    "    if name == 'linear':\n",
    "        return tf.matmul(x, W) + b\n",
    "    elif name == 'tanh':\n",
    "        return tf.nn.tanh(tf.matmul(x, W) + b)\n",
    "    elif name == 'sigmoid':\n",
    "        return tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "    elif name == 'leakyReLU':\n",
    "        return tf.nn.leaky_relu(tf.matmul(x, W) + b)\n",
    "    elif name == 'ReLU':\n",
    "        return tf.nn.relu(tf.matmul(x, W) + b)\n",
    "        \n",
    "        \n",
    "    # different activation functions\n",
    "    # you can try\n",
    "    # (1) linear activation (not a good idea)\n",
    "    #return tf.matmul(x, W) + b\n",
    "    # (2) tanh activation\n",
    "    #return tf.nn.tanh(tf.matmul(x, W) + b)\n",
    "    # (3) sigmoid activation\n",
    "    #return tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "    # (4) relu activation\n",
    "    else:\n",
    "        return tf.nn.relu(tf.matmul(x, W) + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    \"\"\"\n",
    "    define the whole network (5 hidden layers + output layers)\n",
    "    input:\n",
    "        - a batch of pictures \n",
    "        (input shape = (batch_size*image_size))\n",
    "    output:\n",
    "        - a batch vector corresponding to the logits predicted by the network\n",
    "        (output shape = (batch_size*output_size)) \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"hidden_layer_1\"):\n",
    "        hidden_1 = layer(x, [input_size, n_hidden_1], [n_hidden_1],'sigmoid')\n",
    "        #print([input_size, n_hidden_1])\n",
    "     \n",
    "    with tf.variable_scope(\"hidden_layer_2\"):\n",
    "        hidden_2 = layer(hidden_1, [n_hidden_1, n_hidden_2], [n_hidden_2],'tanh')\n",
    "        #print([n_hidden_1, n_hidden_2])\n",
    "        \n",
    "    with tf.variable_scope(\"hidden_layer_3\"):\n",
    "        hidden_3 = layer(hidden_2, [n_hidden_2, n_hidden_3], [n_hidden_3],'sigmoid')\n",
    "        #print([n_hidden_2, n_hidden_3])\n",
    "        \n",
    "    with tf.variable_scope(\"hidden_layer_4\"):\n",
    "        hidden_4 = layer(hidden_3, [n_hidden_3, n_hidden_4], [n_hidden_4],'ReLU')\n",
    "        #print([n_hidden_3, n_hidden_4])\n",
    "        \n",
    "    with tf.variable_scope(\"hidden_layer_5\"):\n",
    "        hidden_5 = layer(hidden_4, [n_hidden_4, n_hidden_5], [n_hidden_5],'leakyReLU')\n",
    "        #print([n_hidden_4, n_hidden_5])\n",
    "     \n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_5, [n_hidden_5, output_size], [output_size], name=None)\n",
    "        #print([n_hidden_5, output_size])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define First Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T22:06:31.251904Z",
     "start_time": "2018-09-17T22:06:31.235310Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_1(output, y):\n",
    "    \"\"\"\n",
    "    computes the average error per data sample \n",
    "    by computing the cross-entropy loss over a minibatch\n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    dot_product = y * tf.log(output)\n",
    "    \n",
    "    #tf.reduce_sum: Computes the sum of elements across dimensions of a tensor.\n",
    "    xentropy = -tf.reduce_sum(dot_product, 1)\n",
    "    \n",
    "    #tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T20:17:03.371287Z",
     "start_time": "2018-09-17T20:17:03.367055Z"
    }
   },
   "source": [
    "## Define Second Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T22:06:31.284838Z",
     "start_time": "2018-09-17T22:06:31.276738Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_2(output, y):\n",
    "    \"\"\"\n",
    "    Computes softmax cross entropy between logits and labels and then the loss \n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #mean square error\n",
    "    #loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-output)))\n",
    "    \n",
    "    #Computes softmax cross entropy between logits and labels.\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the optimizer and training target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T22:06:31.313660Z",
     "start_time": "2018-09-17T22:06:31.305501Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    # tf.train.GradientDescentOptimizer\n",
    "    # will use different optimization routimes \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training2(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    # tf.train.GradientDescentOptimizer\n",
    "    # will use different optimization routimes \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T22:06:31.556011Z",
     "start_time": "2018-09-17T22:06:31.541378Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -y: true value for the validation set\n",
    "    output:\n",
    "        - accuracy: accuracy on the validation set (scalar between 0 and 1)\n",
    "    \"\"\"\n",
    "    #correct prediction is a binary vector which equals one when the output and y match\n",
    "    #otherwise the vector equals 0\n",
    "    #tf.cast: change the type of a tensor into another one\n",
    "    #then, by taking the mean of the tensor, we directly have the average score, so the accuracy\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar(\"validation_error\", (1.0 - accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_1/W:0' shape=(784, 400) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_1/b:0' shape=(400,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_2/W:0' shape=(400, 200) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_2/b:0' shape=(200,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_3/W:0' shape=(200, 100) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_3/b:0' shape=(100,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_4/W:0' shape=(100, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_4/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_5/W:0' shape=(50, 25) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_5/b:0' shape=(25,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/output/W:0' shape=(25, 10) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/output/b:0' shape=(10,) dtype=float32_ref>\n",
      "Epoch: 001 cost function= 1.4809669  Validation Error: 0.26319998502731323\n",
      "Epoch: 003 cost function= 0.4504251  Validation Error: 0.16259998083114624\n",
      "Epoch: 005 cost function= 0.3932213  Validation Error: 0.1525999903678894\n",
      "Epoch: 007 cost function= 0.3608817  Validation Error: 0.149399995803833\n",
      "Epoch: 009 cost function= 0.2597876  Validation Error: 0.04860001802444458\n",
      "Epoch: 011 cost function= 0.0909314  Validation Error: 0.042999982833862305\n",
      "Epoch: 013 cost function= 0.0754269  Validation Error: 0.03960001468658447\n",
      "Epoch: 015 cost function= 0.0628624  Validation Error: 0.037199974060058594\n",
      "Epoch: 017 cost function= 0.0531874  Validation Error: 0.031599998474121094\n",
      "Epoch: 019 cost function= 0.0452046  Validation Error: 0.029999971389770508\n",
      "Epoch: 021 cost function= 0.0390322  Validation Error: 0.029999971389770508\n",
      "Epoch: 023 cost function= 0.0330838  Validation Error: 0.02920001745223999\n",
      "Epoch: 025 cost function= 0.0288290  Validation Error: 0.029600024223327637\n",
      "Epoch: 027 cost function= 0.0250368  Validation Error: 0.024200022220611572\n",
      "Epoch: 029 cost function= 0.0215416  Validation Error: 0.02679997682571411\n",
      "Epoch: 031 cost function= 0.0184029  Validation Error: 0.022599995136260986\n",
      "Epoch: 033 cost function= 0.0160746  Validation Error: 0.023000001907348633\n",
      "Epoch: 035 cost function= 0.0140571  Validation Error: 0.023000001907348633\n",
      "Epoch: 037 cost function= 0.0119321  Validation Error: 0.021799981594085693\n",
      "Epoch: 039 cost function= 0.0106454  Validation Error: 0.021600008010864258\n",
      "Epoch: 041 cost function= 0.0092722  Validation Error: 0.021000027656555176\n",
      "Epoch: 043 cost function= 0.0079761  Validation Error: 0.022000014781951904\n",
      "Epoch: 045 cost function= 0.0070556  Validation Error: 0.02240002155303955\n",
      "Epoch: 047 cost function= 0.0061821  Validation Error: 0.02499997615814209\n",
      "Epoch: 049 cost function= 0.0054619  Validation Error: 0.021399974822998047\n",
      "Epoch: 051 cost function= 0.0046734  Validation Error: 0.022000014781951904\n",
      "Epoch: 053 cost function= 0.0041575  Validation Error: 0.02120000123977661\n",
      "Epoch: 055 cost function= 0.0035413  Validation Error: 0.021600008010864258\n",
      "Epoch: 057 cost function= 0.0032615  Validation Error: 0.020200014114379883\n",
      "Epoch: 059 cost function= 0.0029329  Validation Error: 0.019800007343292236\n",
      "Epoch: 061 cost function= 0.0027709  Validation Error: 0.019999980926513672\n",
      "Epoch: 063 cost function= 0.0023571  Validation Error: 0.020799994468688965\n",
      "Epoch: 065 cost function= 0.0023162  Validation Error: 0.019200026988983154\n",
      "Epoch: 067 cost function= 0.0021788  Validation Error: 0.019599974155426025\n",
      "Epoch: 069 cost function= 0.0019424  Validation Error: 0.019599974155426025\n",
      "Epoch: 071 cost function= 0.0016851  Validation Error: 0.019599974155426025\n",
      "Epoch: 073 cost function= 0.0019005  Validation Error: 0.019999980926513672\n",
      "Epoch: 075 cost function= 0.0015605  Validation Error: 0.019599974155426025\n",
      "Epoch: 077 cost function= 0.0013420  Validation Error: 0.018999993801116943\n",
      "Epoch: 079 cost function= 0.0013483  Validation Error: 0.018800020217895508\n",
      "Epoch: 081 cost function= 0.0011843  Validation Error: 0.01940000057220459\n",
      "Epoch: 083 cost function= 0.0010838  Validation Error: 0.01940000057220459\n",
      "Epoch: 085 cost function= 0.0010325  Validation Error: 0.01819998025894165\n",
      "Epoch: 087 cost function= 0.0009872  Validation Error: 0.018800020217895508\n",
      "Epoch: 089 cost function= 0.0009945  Validation Error: 0.019599974155426025\n",
      "Epoch: 091 cost function= 0.0009089  Validation Error: 0.018800020217895508\n",
      "Epoch: 093 cost function= 0.0009842  Validation Error: 0.019599974155426025\n",
      "Epoch: 095 cost function= 0.0008404  Validation Error: 0.018800020217895508\n",
      "Epoch: 097 cost function= 0.0008188  Validation Error: 0.018800020217895508\n",
      "Epoch: 099 cost function= 0.0007988  Validation Error: 0.018999993801116943\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.9761\n",
      "Execution time (seconds) was 481.540\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #please, make sure you changed for your own path \n",
    "    log_files_path = 'C:/Users/Ali/logs/'\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        with tf.variable_scope(\"multi_5_layer\"):\n",
    "            #neural network definition \n",
    "            \n",
    "            #the input variables are first define as placeholder \n",
    "            # a placeholder is a variable/data which will be assigned later \n",
    "            # image vector & label\n",
    "            x = tf.placeholder(\"float\", [None, input_size])   # MNIST data image of shape 28*28=784\n",
    "            y = tf.placeholder(\"float\", [None, output_size])  # 0-9 digits recognition\n",
    "\n",
    "            #the network is defined using the inference function defined above in the code\n",
    "            output = inference(x)\n",
    "            #calculate loss with tensorflow's cross-entropy function\n",
    "            cost = loss_2(output, y)\n",
    "            \n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            \n",
    "            train_op = training(cost, global_step)\n",
    "            #train_op = training(cost, global_step=None)\n",
    "            \n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            eval_op = evaluate(output, y)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "    \n",
    "            #save and restore variables to and from checkpoints.\n",
    "            saver = tf.train.Saver()\n",
    "    \n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "            \n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #\n",
    "            summary_writer = tf.summary.FileWriter(log_files_path+'multi_5_layer/', sess.graph)\n",
    "        \n",
    "            #initialization of all the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "        \n",
    "            #will work with this later\n",
    "            #saver.restore(sess, log_files_path+'multi_layer/model-checkpoint-66000')\n",
    "            \n",
    "            loss_trace = []\n",
    "\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(mnist.train.num_examples/batch_size)\n",
    "            \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "\n",
    "                    minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    # Compute average loss of all batches\n",
    "                    avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y})/total_batch\n",
    "                    \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    \n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "                    loss_trace.append(1-accuracy)    \n",
    "                    print(\"Epoch:\", '%03d' % (epoch+1), \"cost function=\", \"{:0.7f}\".format(avg_cost), \" Validation Error:\", (1.0 - accuracy))\n",
    "                    summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "                        \n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    saver.save(sess, log_files_path+'multi_5_layer/model-checkpoint', global_step=global_step)\n",
    "                        \n",
    "            print(\"Optimization Finished!\")\n",
    "            #accuracy evaluated with the whole test dataset\n",
    "            accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "            print(\"Test Accuracy:\", accuracy)\n",
    "                    \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('Execution time (seconds) was %0.3f' % elapsed_time)\n",
    "            \n",
    "            # Visualization of the results\n",
    "            # loss function\n",
    "            plt.plot(loss_trace)\n",
    "            plt.title('Cross Entropy Loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(c) for part (b) keep the same architecture, just use different optimization routine and assess its impact on accuracy?\n",
    "\n",
    "using Adam in this case\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_1/W:0' shape=(784, 400) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_1/b:0' shape=(400,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_2/W:0' shape=(400, 200) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_2/b:0' shape=(200,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_3/W:0' shape=(200, 100) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_3/b:0' shape=(100,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_4/W:0' shape=(100, 50) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_4/b:0' shape=(50,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/hidden_layer_5/W:0' shape=(50, 25) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/hidden_layer_5/b:0' shape=(25,) dtype=float32_ref>\n",
      "Weight Matrix: <tf.Variable 'multi_5_layer/output/W:0' shape=(25, 10) dtype=float32_ref>\n",
      "Bias Vector: <tf.Variable 'multi_5_layer/output/b:0' shape=(10,) dtype=float32_ref>\n",
      "Epoch: 001 cost function= 2.3040651  Validation Error: 0.9042000025510788\n",
      "Epoch: 003 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 005 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 007 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 009 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 011 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 013 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 015 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 017 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 019 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 021 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 023 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 025 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 027 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 029 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 031 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 033 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 035 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 037 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 039 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 041 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 043 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 045 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 047 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 049 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 051 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 053 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 055 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 057 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 059 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 061 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 063 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 065 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 067 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 069 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 071 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 073 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 075 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 077 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 079 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 081 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 083 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 085 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 087 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 089 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 091 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 093 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 095 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 097 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Epoch: 099 cost function= 2.3025854  Validation Error: 0.9042000025510788\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.098\n",
      "Execution time (seconds) was 530.491\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAF0NJREFUeJzt3X+cXXV95/HXGwKiQkBJtJIAQaVd4hZQplS3ulJwaWCtqPgDBAquD9l9VPrQVVRQumIstT+opVuxLa0UFBURxdLKFmkKaLuoTICgiGhkgYSgCYL8EBECn/3jnNHLGOY74FwmM/N6Ph73Med8z/fc8/lObu77nu+Ze2+qCkmSJrLFdBcgSdr8GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFNhtJ3pBkNMm9SW5L8n+SvHga6zkryQN9PWO3VZPc9+Qk5wy7xslKclOSl013HZq5DAttFpK8HTgN+EPgmcAuwEeAQx6l/7wnqLQ/qaptB257TcWdpuP/P80YPlg17ZJsDywH3lJVn6uqH1XVg1X1j1X1zr7PyUnOT3JOkruBY5I8KclpSdb1t9OSPKnvvyDJPyX5YZI7knx57Mk5ybuT3JrkniQ3JDngcdS8JEklOTrJLUluT/Leftsy4D3A6wfPRpJcluSUJP8O3Ac8O8lOSS7sa1yd5M0Dxxgb86f7Wq9Ksle/7Z1JPjuupr9MctrjGMub+2Pf0deyU9+eJH+eZH2Su5Jcm+Q/9tsOTvLNvq5bkxz/WI+rGaaqvHmb1huwDNgIzJugz8nAg8Ar6V7kPJkuYL4CPANYCPxf4AN9/w8Cfw1s1d9eAgT4FWANsFPfbwnwnEc55lnAHzzKtiVAAX/b17IX8BNgj4F6zxm3z2XALcDzgHl9XZfTnUFtA+wNbAAOGDfm1/R9jwf+X7/8LOBHwA5933nAemCfR6n3JuBlm2jfH7gdeAHwJOAvgS/1234LWAns0P/u9gCe1W+7DXhJv/w04AXT/TjyNtybZxbaHOwI3F5VGxv9rqiqz1fVw1X1Y+AIYHlVra+qDcD7gaP6vg/SPaHuWt1ZyperqoCH6J4UlybZqqpuqqrvTnDM4/uzk7Hb2eO2v7+qflxVq4BVdKExkbOq6rp+rL8EvBh4d1XdX1XXAH83MAaAlVV1flU9CHyILlReWFW3AV8CXtv3W0b3O1zZOP54RwBnVtVVVfUT4ETgRUmW0P0OtwP+A5Cqur4/Lv22pUnmV9WdVXXVYzyuZhjDQpuDHwALJnEdYs249Z2AmwfWb+7bAP4UWA18McmNSU4AqKrVwNvoXrWvT3Lu2LTLozi1qnYYuB09bvv3BpbvA7Z9DGPYCbijqu4ZN4ZFm+pfVQ8DawfGeDZwZL98JPDxxrE35RG/w6q6l+7fY1FV/SvwYeB04PtJzkgyv+96KHAwcHOSy5O86HEcWzOIYaHNwRXA/XRTTBMZ/xHJ64BdB9Z36duoqnuq6h1V9Wzgt4G3j12bqKpPVtWL+30L+ONffAjNWjfVvg54epLtBtp2AW4dWN95bKG/5rK43w/g88Ce/XWElwOfeBx1PuJ3mOSpdGd6twJU1f+uqn3ops5+GXhn335lVR1CNwX4eeC8x3FszSCGhaZdVd0F/C/g9CSvTPKUJFslOSjJn0yw66eAk5IsTLKgv49zAJK8PMlzkwS4m2766aEkv5Jk//5C+P3Aj/ttU+37wJKJ/uKpqtbQXWf5YJJtkuwJvIlHPunvk+TV/VnX2+iui3yl3/9+4Hzgk8DXquqWRk1b9ccZu83r931jkr3738kfAl+tqpuS/FqSX0+yFd31kfvpfodbJzkiyfb99NjY71ezmGGhzUJVfQh4O3AS3UXeNcBxdK9aH80fAKPAtcDXgav6NoDdgX8B7qU7c/lIVV1Gd73ij+gu6n6P7pXxeyY4xrvyyPdZ3D7JIX2m//mDJBPN5x9Od7F8HXAB8L6qumRg+z8ArwfupLuW8er+CXrM2cCvMrkpqIvownHsdnJVrQB+H/gs3UXr5wCH9f3n013Av5NuquoHwKn9tqOAm/q/TPsf/Gw6TLNUumt+kjY3SU4GnltVj/pEnGQX4FvAL1XV3U9UbZp7PLOQZqh+iuvtwLkGhYbtiXoXrKQp1F+I/j7d9NCyaS5Hc4DTUJKkJqehJElNs2YaasGCBbVkyZLpLkOSZpSVK1feXlULW/1mTVgsWbKE0dHR6S5DkmaUJDe3ezkNJUmaBMNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktQ01LBIsizJDUlWJzlhE9t3TbIiybVJLkuyeNz2+UluTfLhYdYpSZrY0MIiyZbA6cBBwFLg8CRLx3U7FfhYVe0JLAc+OG77B4DLh1WjJGlyhnlmsS+wuqpurKoHgHOBQ8b1WQqs6JcvHdyeZB/gmcAXh1ijJGkShhkWi4A1A+tr+7ZBq4BD++VXAdsl2THJFsCfAe+c6ABJjk0ymmR0w4YNU1S2JGm8YYZFNtFW49aPB16a5GrgpcCtwEbgd4GLqmoNE6iqM6pqpKpGFi5cOBU1S5I2Yd4Q73stsPPA+mJg3WCHqloHvBogybbAoVV1V5IXAS9J8rvAtsDWSe6tqp+7SC5JGr5hhsWVwO5JdqM7YzgMeMNghyQLgDuq6mHgROBMgKo6YqDPMcCIQSFJ02do01BVtRE4DrgYuB44r6quS7I8ySv6bvsBNyT5Nt3F7FOGVY8k6fFL1fjLCDPTyMhIjY6OTncZkjSjJFlZVSOtfr6DW5LUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKahhoWSZYluSHJ6iQnbGL7rklWJLk2yWVJFvfteye5Isl1/bbXD7NOSdLEhhYWSbYETgcOApYChydZOq7bqcDHqmpPYDnwwb79PuB3qup5wDLgtCQ7DKtWSdLEhnlmsS+wuqpurKoHgHOBQ8b1WQqs6JcvHdteVd+uqu/0y+uA9cDCIdYqSZrAMMNiEbBmYH1t3zZoFXBov/wqYLskOw52SLIvsDXw3SHVKUlqGGZYZBNtNW79eOClSa4GXgrcCmz86R0kzwI+Dryxqh7+uQMkxyYZTTK6YcOGqatckvQIwwyLtcDOA+uLgXWDHapqXVW9uqqeD7y3b7sLIMl84AvASVX1lU0doKrOqKqRqhpZuNBZKkkalmGGxZXA7kl2S7I1cBhw4WCHJAuSjNVwInBm3741cAHdxe/PDLFGSdIkDC0sqmojcBxwMXA9cF5VXZdkeZJX9N32A25I8m3gmcApffvrgP8MHJPkmv6297BqlSRNLFXjLyPMTCMjIzU6OjrdZUjSjJJkZVWNtPr5Dm5JUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1DSpsEjy1iTz0/lokquSHDjs4iRJm4fJnln8t6q6GzgQWAi8EfijoVUlSdqsTDYs0v88GPj7qlo10CZJmuUmGxYrk3yRLiwuTrId8PDwypIkbU7mTbLfm4C9gRur6r4kT6ebipIkzQGTDYsXAddU1Y+SHAm8APiL4ZX1xHr/P17HN9fdPd1lSNLjsnSn+bzvt5831GNMdhrqr4D7kuwFvAu4GfjY0KqSJG1WJntmsbGqKskhwF9U1UeTHD3Mwp5Iw05kSZrpJhsW9yQ5ETgKeEmSLYGthleWJGlzMtlpqNcDP6F7v8X3gEXAnw6tKknSZmVSYdEHxCeA7ZO8HLi/qrxmIUlzxGQ/7uN1wNeA1wKvA76a5DXDLEyStPmY7DTUe4Ffq6qjq+p3gH2B32/tlGRZkhuSrE5ywia275pkRZJrk1yWZPHAtqOTfKe/zZqL6ZI0E002LLaoqvUD6z9o7dtfBD8dOAhYChyeZOm4bqcCH6uqPYHlwAf7fZ8OvA/4dbpgel+Sp02yVknSFJtsWPxzkouTHJPkGOALwEWNffYFVlfVjVX1AHAucMi4PkuBFf3ypQPbfwu4pKruqKo7gUuAZZOsVZI0xSZ7gfudwBnAnsBewBlV9e7GbouANQPra/u2QauAQ/vlVwHbJdlxkvuS5Ngko0lGN2zYMJmhSJIeh8m+z4Kq+izw2cdw35v6VNoat3488OH+bOVLwK3AxknuS1WdQRdijIyM/Nx2SdLUmDAsktzDJp6k6Z7Mq6rmT7D7WmDngfXFwLrBDlW1Dnh1f6xtgUOr6q4ka4H9xu172US1SpKGZ8JpqKrarqrmb+K2XSMoAK4Edk+yW5KtgcOACwc7JFmQZKyGE4Ez++WLgQOTPK2/sH1g3yZJmgZD+w7uqtoIHEf3JH89cF5VXZdkeZJX9N32A25I8m3gmcAp/b53AB+gC5wrgeV9myRpGqRqdkz1j4yM1Ojo6HSXIUkzSpKVVTXS6je0MwtJ0uxhWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lS01DDIsmyJDckWZ3khE1s3yXJpUmuTnJtkoP79q2SnJ3k60muT3LiMOuUJE1saGGRZEvgdOAgYClweJKl47qdBJxXVc8HDgM+0re/FnhSVf0qsA/w35MsGVatkqSJDfPMYl9gdVXdWFUPAOcCh4zrU8D8fnl7YN1A+1OTzAOeDDwA3D3EWiVJExhmWCwC1gysr+3bBp0MHJlkLXAR8Ht9+/nAj4DbgFuAU6vqjvEHSHJsktEkoxs2bJji8iVJY4YZFtlEW41bPxw4q6oWAwcDH0+yBd1ZyUPATsBuwDuSPPvn7qzqjKoaqaqRhQsXTm31kqSfGmZYrAV2HlhfzM+mmca8CTgPoKquALYBFgBvAP65qh6sqvXAvwMjQ6xVkjSBYYbFlcDuSXZLsjXdBewLx/W5BTgAIMkedGGxoW/fP52nAi8EvjXEWiVJExhaWFTVRuA44GLgerq/erouyfIkr+i7vQN4c5JVwKeAY6qq6P6KalvgG3Sh8/dVde2wapUkTSzdc/PMNzIyUqOjo9NdhiTNKElWVlVzmt93cEuSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoaalgkWZbkhiSrk5ywie27JLk0ydVJrk1y8MC2PZNckeS6JF9Pss0wa5UkPbp5w7rjJFsCpwP/BVgLXJnkwqr65kC3k4DzquqvkiwFLgKWJJkHnAMcVVWrkuwIPDisWiVJExvmmcW+wOqqurGqHgDOBQ4Z16eA+f3y9sC6fvlA4NqqWgVQVT+oqoeGWKskaQLDDItFwJqB9bV926CTgSOTrKU7q/i9vv2XgUpycZKrkrxrUwdIcmyS0SSjGzZsmNrqJUk/NcywyCbaatz64cBZVbUYOBj4eJIt6KbHXgwc0f98VZIDfu7Oqs6oqpGqGlm4cOHUVi9J+qlhhsVaYOeB9cX8bJppzJuA8wCq6gpgG2BBv+/lVXV7Vd1Hd9bxgiHWKkmawDDD4kpg9yS7JdkaOAy4cFyfW4ADAJLsQRcWG4CLgT2TPKW/2P1S4JtIkqbF0P4aqqo2JjmO7ol/S+DMqrouyXJgtKouBN4B/G2S/0k3RXVMVRVwZ5IP0QVOARdV1ReGVaskaWLpnptnvpGRkRodHZ3uMiRpRkmysqpGWv18B7ckqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lS06z509kkG4Cbf4G7WADcPkXlzCSOe25x3HPLZMa9a1U1Py9p1oTFLyrJ6GT+1ni2cdxzi+OeW6Zy3E5DSZKaDAtJUpNh8TNnTHcB08Rxzy2Oe26ZsnF7zUKS1OSZhSSpybCQJDXN+bBIsizJDUlWJzlhuusZpiRnJlmf5BsDbU9PckmS7/Q/nzadNU61JDsnuTTJ9UmuS/LWvn22j3ubJF9Lsqof9/v79t2SfLUf96f7LyabdZJsmeTqJP/Ur8+Vcd+U5OtJrkky2rdNyWN9TodFki2B04GDgKXA4UmWTm9VQ3UWsGxc2wnAiqraHVjRr88mG4F3VNUewAuBt/T/xrN93D8B9q+qvYC9gWVJXgj8MfDn/bjvpPtq49norcD1A+tzZdwAv1lVew+8v2JKHutzOiyAfYHVVXVjVT0AnAscMs01DU1VfQm4Y1zzIcDZ/fLZwCuf0KKGrKpuq6qr+uV76J5AFjH7x11VdW+/ulV/K2B/4Py+fdaNGyDJYuC/An/Xr4c5MO4JTMljfa6HxSJgzcD62r5tLnlmVd0G3RMr8IxprmdokiwBng98lTkw7n4q5hpgPXAJ8F3gh1W1se8yWx/vpwHvAh7u13dkbowbuhcEX0yyMsmxfduUPNaH9h3cM0Q20ebfEs9CSbYFPgu8raru7l5szm5V9RCwd5IdgAuAPTbV7YmtariSvBxYX1Urk+w31ryJrrNq3AN+o6rWJXkGcEmSb03VHc/1M4u1wM4D64uBddNUy3T5fpJnAfQ/109zPVMuyVZ0QfGJqvpc3zzrxz2mqn4IXEZ3zWaHJGMvEmfj4/03gFckuYluWnl/ujON2T5uAKpqXf9zPd0LhH2Zosf6XA+LK4Hd+7+U2Bo4DLhwmmt6ol0IHN0vHw38wzTWMuX6+eqPAtdX1YcGNs32cS/szyhI8mTgZXTXay4FXtN3m3XjrqoTq2pxVS2h+//8r1V1BLN83ABJnppku7Fl4EDgG0zRY33Ov4M7ycF0rzy2BM6sqlOmuaShSfIpYD+6jy3+PvA+4PPAecAuwC3Aa6tq/EXwGSvJi4EvA1/nZ3PY76G7bjGbx70n3cXMLeleFJ5XVcuTPJvuFffTgauBI6vqJ9NX6fD001DHV9XL58K4+zFe0K/OAz5ZVack2ZEpeKzP+bCQJLXN9WkoSdIkGBaSpCbDQpLUZFhIkpoMC0lSk2EhbQaS7Df2CanS5siwkCQ1GRbSY5DkyP57Iq5J8jf9h/Xdm+TPklyVZEWShX3fvZN8Jcm1SS4Y+x6BJM9N8i/9d01cleQ5/d1vm+T8JN9K8onMhQ+w0oxhWEiTlGQP4PV0H9a2N/AQcATwVOCqqnoBcDndO+MBPga8u6r2pHsH+Vj7J4DT+++a+E/AbX3784G30X23yrPpPudI2izM9U+dlR6LA4B9gCv7F/1PpvtQtoeBT/d9zgE+l2R7YIequrxvPxv4TP/ZPYuq6gKAqrofoL+/r1XV2n79GmAJ8G/DH5bUZlhIkxfg7Ko68RGNye+P6zfRZ+hMNLU0+FlFD+H/T21GnIaSJm8F8Jr+uwLGvtt4V7r/R2OfaPoG4N+q6i7gziQv6duPAi6vqruBtUle2d/Hk5I85QkdhfQ4+MpFmqSq+maSk+i+iWwL4EHgLcCPgOclWQncRXddA7qPg/7rPgxuBN7Ytx8F/E2S5f19vPYJHIb0uPips9IvKMm9VbXtdNchDZPTUJKkJs8sJElNnllIkpoMC0lSk2EhSWoyLCRJTYaFJKnp/wOUaIiw+jwxmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #please, make sure you changed for your own path \n",
    "    log_files_path = '/Users/liyingellie/Downloads'\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        with tf.variable_scope(\"multi_5_layer\"):\n",
    "            #neural network definition \n",
    "            \n",
    "            #the input variables are first define as placeholder \n",
    "            # a placeholder is a variable/data which will be assigned later \n",
    "            # image vector & label\n",
    "            x = tf.placeholder(\"float\", [None, input_size])   # MNIST data image of shape 28*28=784\n",
    "            y = tf.placeholder(\"float\", [None, output_size])  # 0-9 digits recognition\n",
    "\n",
    "            #the network is defined using the inference function defined above in the code\n",
    "            output = inference(x)\n",
    "            #calculate loss with tensorflow's cross-entropy function\n",
    "            cost = loss_2(output, y)\n",
    "            \n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            \n",
    "            train_op = training2(cost, global_step)\n",
    "            #train_op = training(cost, global_step=None)\n",
    "            \n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            eval_op = evaluate(output, y)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "    \n",
    "            #save and restore variables to and from checkpoints.\n",
    "            saver = tf.train.Saver()\n",
    "    \n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "            \n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #\n",
    "            summary_writer = tf.summary.FileWriter(log_files_path+'multi_5_layer/', sess.graph)\n",
    "        \n",
    "            #initialization of all the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "        \n",
    "            #will work with this later\n",
    "            #saver.restore(sess, log_files_path+'multi_layer/model-checkpoint-66000')\n",
    "            \n",
    "            loss_trace = []\n",
    "\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(mnist.train.num_examples/batch_size)\n",
    "            \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "\n",
    "                    minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    # Compute average loss of all batches\n",
    "                    avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y})/total_batch\n",
    "                    \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    \n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "                    loss_trace.append(1-accuracy)    \n",
    "                    print(\"Epoch:\", '%03d' % (epoch+1), \"cost function=\", \"{:0.7f}\".format(avg_cost), \" Validation Error:\", (1.0 - accuracy))\n",
    "                    summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                    summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "                        \n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    saver.save(sess, log_files_path+'multi_5_layer/model-checkpoint', global_step=global_step)\n",
    "                        \n",
    "            print(\"Optimization Finished!\")\n",
    "            #accuracy evaluated with the whole test dataset\n",
    "            accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "            print(\"Test Accuracy:\", accuracy)\n",
    "                    \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('Execution time (seconds) was %0.3f' % elapsed_time)\n",
    "            \n",
    "            # Visualization of the results\n",
    "            # loss function\n",
    "            \n",
    "            plt.plot(loss_trace)\n",
    "            plt.title('Cross Entropy Loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "            #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Problem 2 (visualization of the lost function ): Use sample code example 5 layer interpolation.jpynb and architecture and opti-\n",
    "mization routine in parts (b) & (c) of Problem 1 to assess the loss function by interpolation, namely\n",
    "(a) impact of different architecture on the loss function surface\n",
    "(b) assessing the path traveled through the loss function having same architecture but using different optimization routine\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
